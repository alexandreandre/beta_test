import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

def extraire_page_connectee(url, nom_fichier_sortie, cookies_session):
    """
    Extrait le HTML et le CSS d'une page web n√©cessitant une connexion,
    en utilisant un cookie de session, et sauvegarde le tout dans un unique fichier HTML.

    Args:
        url (str): L'URL de la page web √† traiter.
        nom_fichier_sortie (str): Le nom du fichier HTML de sortie.
        cookies_session (dict): Un dictionnaire contenant les cookies de session.
    """
    try:
        # La requ√™te inclut maintenant votre cookie pour √™tre authentifi√©
        reponse = requests.get(url, cookies=cookies_session)
        reponse.raise_for_status()  # L√®ve une exception pour les codes d'erreur HTTP

        print("‚úÖ Acc√®s √† la page en mode connect√© r√©ussi !")

        soup = BeautifulSoup(reponse.text, 'html.parser')

        # Trouver et int√©grer les feuilles de style externes
        print("üîé Recherche des fichiers CSS...")
        for lien in soup.find_all('link', rel='stylesheet'):
            href = lien.get('href')
            if href:
                # Construit une URL absolue pour le fichier CSS
                url_css = urljoin(url, href)
                try:
                    # On r√©utilise les cookies de session pour t√©l√©charger le CSS
                    # au cas o√π il serait aussi prot√©g√©.
                    css_reponse = requests.get(url_css, cookies=cookies_session)
                    css_reponse.raise_for_status()
                    
                    # Remplacer le lien <link> par une balise <style> avec le contenu CSS
                    style_tag = soup.new_tag('style')
                    style_tag.string = css_reponse.text
                    lien.replace_with(style_tag)
                    print(f"   -> CSS int√©gr√© depuis : {url_css}")
                except requests.exceptions.RequestException as e:
                    print(f"   ‚ö†Ô∏è Impossible de t√©l√©charger le CSS depuis {url_css}: {e}")

        # Sauvegarder le HTML modifi√©
        with open(nom_fichier_sortie, 'w', encoding='utf-8') as f:
            f.write(str(soup))
            
        print(f"\nüéâ La page a √©t√© sauvegard√©e avec succ√®s sous le nom de : {nom_fichier_sortie}")

    except requests.exceptions.RequestException as e:
        print(f"‚ùå Une erreur est survenue lors du t√©l√©chargement de la page : {e}")

# --- CONFIGURATION ---
if __name__ == '__main__':
    # 1. Mettez ici l'URL exacte de la page que vous voulez sauvegarder
    url_de_la_page = "https://www.legisocial.fr/modele-bulletin-paie/salarie-cadre-heures-supplementaires-structurelles-absence-maintenue-2025.html"

    # 2. Donnez un nom au fichier qui sera cr√©√©
    nom_du_fichier = "page_legisocial_connecte.html"

    # 3. C'est ici que vous mettez votre cookie de session
    # Le nom 'PHPSESSID' et sa valeur proviennent de votre analyse pr√©c√©dente.
    vos_cookies = {
        'PHPSESSID': 'o8h8d358jtlii0vn6vof0a2vvf'
    }

    # --- EX√âCUTION DU SCRIPT ---
    extraire_page_connectee(url_de_la_page, nom_du_fichier, vos_cookies)